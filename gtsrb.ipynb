{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:b8c3d4f33c628fca64e7f58f066c9a040057ad233110b6cbd2873b1d490095d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "-- install csv module with >$ luarocks install csv\n",
      "\n",
      "Here we only require the packages that are necessary for the optimization and visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'image';\n",
      "require 'xlua';\n",
      "require 'optim';"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preprocessing rescales the images to 32x32. The color variable says if it should stay color (YUV) or gray (Y). The data then gets whitened then returns them as \"torch dataset\" variables named trainData and testData."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color = false\n",
      "dofile('preprocess.lua');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "Loading data!\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "Data is ready for work!\t\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "We then configure the deep model. We have a very simple configuration system : config picks one of the configurations from configure.lua and cuda says whether it should be run on the GPU or not. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = 3\n",
      "cuda = true\n",
      "\n",
      "dofile('configure.lua')\n",
      "print(model:__tostring())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "Configuration 3\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "cuda\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "nn.Sequential {\n",
        "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> output]\n",
        "  (1): nn.SpatialContrastiveNormalization\n",
        "  (2): nn.SpatialConvolutionMM(in: 1, out: 100, kW: 5, kH: 5)\n",
        "  (3): nn.Tanh\n",
        "  (4): nn.ReLU\n",
        "  (5): nn.SpatialSubtractiveNormalization\n",
        "  (6): nn.SpatialDivisiveNormalization\n",
        "  (7): nn.SpatialMaxPooling(kW: 2, kH: 2, dW: 2, dH: 2)\n",
        "  (8): nn.SpatialConvolutionMM(in: 100, out: 200, kW: 5, kH: 5)\n",
        "  (9): nn.Tanh\n",
        "  (10): nn.ReLU\n",
        "  (11): nn.SpatialSubtractiveNormalization\n",
        "  (12): nn.SpatialDivisiveNormalization\n",
        "  (13): nn.SpatialMaxPooling(kW: 2, kH: 2, dW: 2, dH: 2)\n",
        "  (14): nn.Reshape(5000)\n",
        "  (15): nn.Linear(5000 -> 100)\n",
        "  (16): nn.Tanh\n",
        "  (17): nn.Linear(100 -> 43)\n",
        "  (18): nn.Tanh\n",
        "  (19): nn.Reshape(43)\n",
        "}\t\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Here we run the actual training. Nothing more special than StochasticGradient with momentum and weight decay."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config=3\n",
      "dofile('preprocess.lua')\n",
      "dofile('configure.lua')\n",
      "trainer = nn.StochasticGradient(model, criterion)\n",
      "trainer.learningRate = learningRate\n",
      "trainer.learningRateDecay = 1e-7\n",
      "trainer.momentum = .9\n",
      "\n",
      "trainer.maxIteration = maxIt\n",
      "trainer.shuffleIndices = true\n",
      "trainer.verbose = true\n",
      "\n",
      "-- now run training\n",
      "trainer:train(trainData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "Loading data!\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "Data is ready for work!\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "Configuration 3\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "cuda\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# StochasticGradient: training\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 2,1025270875179\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9453297815649\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9316258330121\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9222097903118\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9180702300195\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9193880644723\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9133078035424\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9113254789642\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9076074356906\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9084107702984\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9055245856854\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9058742247714\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9042824089086\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9042674517455\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "# current error = 1,9045248961698\t\n",
        "# StochasticGradient: you have reached the maximum number of iterations\t\n",
        "# training error = 1,9045248961698\t\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Here we assess results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correct = 0\n",
      "dataset = testData;\n",
      "--dataset = trainData;\n",
      "\n",
      "predLabel = torch.Tensor(dataset:size()):zero()\n",
      "for i=1,dataset:size() do\n",
      "    local groundtruth = dataset.label[i]\n",
      "    local prediction = model:forward(dataset.data[i])\n",
      "    local confidences, indices = torch.max(prediction,1)\n",
      "    if groundtruth == indices[1] then\n",
      "        correct = correct + 1\n",
      "    end\n",
      "    predLabel[i] = indices[1]\n",
      "end\n",
      "print(correct, 100*correct/dataset:size() .. ' % ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "12194\t96,547901821061 % \t\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matching result using last FC layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ra = utils.matching_accuracy(model,18,trainData,testData)\n",
      "print('Matching accuracy on the test set ' .. ra .. ' % ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "Matching accuracy on the test set 96,357878068092 % \t\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matching result using the last convolutional layer (after its non-linearities)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ra = utils.matching_accuracy(model,14,trainData,testData)\n",
      "print('Matching accuracy on the test set ' .. ra .. ' % ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "Matching accuracy on the test set 86,112430720507 % \t\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------------------------------------------------------------------------------------------------------------\n",
      "-------------------------------          END                   -----------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------------"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}